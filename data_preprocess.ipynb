{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_preprocess",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2yYXnSyxi2FUWmTtGsdzx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vishal-ib97/Developer-Name-Disambiguation/blob/main/data_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA7J4lX_FqWh"
      },
      "source": [
        "import requests\r\n",
        "from IPython.core.display import HTML\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import datetime\r\n",
        "import os\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import sys\r\n",
        "import re\r\n",
        "import unicodedata"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AblHe6s8TnDu",
        "outputId": "7e934fbd-a682-4b1e-f383-ee607e370466"
      },
      "source": [
        "#mount drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zal6Q-UTx_2"
      },
      "source": [
        "new_df = pd.read_csv(\"/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/new_commits_df.csv\")\r\n",
        "com =  pd.read_csv(\"/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/json_data_updated.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fujci6jF84y"
      },
      "source": [
        "#filter projects based on the projects present in the ground truth page\r\n",
        "new_df = new_df[new_df.proj_name.isin(com.project.values)]\r\n",
        "new_df.author_name = new_df.author_name.str.lower()\r\n",
        "new_df.drop_duplicates(subset = ['author_name', 'email_id'], inplace = True)\r\n",
        "new_df.drop(['Unnamed: 0'], axis = 1, inplace = True)\r\n",
        "\r\n",
        "#dealing with Nans in author name\r\n",
        "#checking if the corresponding email ids contain any useful information and filling the rows\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: Scott Boag -->\", \"author_name\"] = \"Scott Boag\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: Scott Boag -->\", \"email_id\"] = \"sboag\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Template for SearchWidget. Author: hearnden@google.com (David Hearnden) -->\", \"author_name\"] = \"David Hearnden\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Template for SearchWidget. Author: hearnden@google.com (David Hearnden) -->\", \"email_id\"] = \"hearnden\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: Jordan Naftolin -->\", \"author_name\"] = \"Jordan Naftolin\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: Jordan Naftolin -->\", \"email_id\"] = \"jordan\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: jeremias.maerki@outline.ch -->\", \"email_id\"] = \"jeremias.maerki\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: jeremias.maerki@outline.ch -->\", \"author_name\"] = \"Jeremias Maerki\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: Paul Dick -->\", \"author_name\"] = \"Paul Dick\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: Paul Dick -->\", \"email_id\"] = \"pauldick\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: shane_curcuru@us.ibm.com -->\", \"author_name\"] = \"Shane Curcuru\"\r\n",
        "new_df.loc[new_df.email_id == \"<!-- Author: shane_curcuru@us.ibm.com -->\", \"email_id\"] = \"shane_curcuru\"\r\n",
        "new_df.to_csv(\"/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/commit_10_proj_df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "iJvY298uG_I0",
        "outputId": "faf320c1-7579-4c46-8714-b662b593153e"
      },
      "source": [
        "g = new_df.groupby('proj_name')\r\n",
        "proj_commit = pd.DataFrame()\r\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proj_name</th>\n",
              "      <th>date_time</th>\n",
              "      <th>author_name</th>\n",
              "      <th>email_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>accumulo</td>\n",
              "      <td>2020-11-02 15:14:00</td>\n",
              "      <td>mike miller</td>\n",
              "      <td>&lt;mmiller@apache.org&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>accumulo</td>\n",
              "      <td>2020-11-03 00:53:00</td>\n",
              "      <td>christopher tubbs</td>\n",
              "      <td>&lt;ctubbsii@apache.org&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>accumulo</td>\n",
              "      <td>2020-11-03 17:39:00</td>\n",
              "      <td>keith turner</td>\n",
              "      <td>&lt;kturner@apache.org&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>accumulo</td>\n",
              "      <td>2020-11-04 18:25:00</td>\n",
              "      <td>jeffrey manno</td>\n",
              "      <td>&lt;jeffreymanno15@gmail.com&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>accumulo</td>\n",
              "      <td>2020-11-04 18:32:00</td>\n",
              "      <td>buildbot</td>\n",
              "      <td>&lt;users@infra.apache.org&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  proj_name  ...                    email_id\n",
              "0  accumulo  ...        <mmiller@apache.org>\n",
              "1  accumulo  ...       <ctubbsii@apache.org>\n",
              "2  accumulo  ...        <kturner@apache.org>\n",
              "3  accumulo  ...  <jeffreymanno15@gmail.com>\n",
              "4  accumulo  ...    <users@infra.apache.org>\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hZCr3nQHAAU"
      },
      "source": [
        "#processing the commit data separately for each project since projects ahve shared contibutors\r\n",
        "\r\n",
        "for pr in g.groups:\r\n",
        "  print(pr)\r\n",
        "  new_df = pd.read_csv(\"/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/commit_10_proj_df.csv\")\r\n",
        "  new_df.drop(['Unnamed: 0'], inplace = True, axis = 1)\r\n",
        "\r\n",
        "  new_df = new_df[new_df.proj_name == pr]\r\n",
        "  new_df.reset_index(inplace = True)\r\n",
        "  np.set_printoptions(threshold=sys.maxsize)\r\n",
        "  pd.set_option('display.max_columns', None)\r\n",
        "\r\n",
        "  com.author_name = com.author_name.str.lower()\r\n",
        "  new_df.author_name = new_df.author_name.str.lower()\r\n",
        "  new_df.author_name = new_df.author_name.astype('str')\r\n",
        "  #new_df.email_id = new_df.email_id.astype('str')\r\n",
        "  new_df = new_df[~new_df.author_name.str.contains(\",\")]\r\n",
        "\r\n",
        "  new_df.author_name = new_df.author_name.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\r\n",
        "  new_df = new_df[new_df.author_name != \"\"]\r\n",
        "\r\n",
        "  def clean_auth_names():\r\n",
        "    df = new_df\r\n",
        "    df.loc[df.email_id == \"barboni\", \"author_name\"] = \"eric barboni\"\r\n",
        "    df.drop(df[df['author_name'].isnull()].index, inplace=True)\r\n",
        "    df['author_name'] = df['author_name'].str.lower()\r\n",
        "    replace_str = [ \",\", \"\\):\", \"/\", \"\\\\\", \"*\", \"$\", \"`\", \"\\'\", \"\\\"\", \"|\", \",\", \" \\)\", \"=\", \"+\", \"#\", \"=\", \"\\[\", \"\\]\", \"?\", \"\\(\\)\\;\", \"\\);\", \";\"]\r\n",
        "    for i in replace_str:\r\n",
        "      df['author_name'] = df['author_name'].str.replace(i,\"\")\r\n",
        "\r\n",
        "    df['author_name'] = df['author_name'].str.replace(\"  \",\" \")\r\n",
        "    bot_str = ['\\[bot\\]', 'buildbot', 'nicerobot', 'github bot', '-bot', 'github actions bot', 'mergebot', 'renovate bot', 'automated github actions', 'auth of last commit', '4 immediate children', 'utf-8', 'entry get author', 'gg@localhost', 'dependabot[bot]']\r\n",
        "    for i in bot_str:\r\n",
        "      df = df.drop(df[df['author_name'].str.contains(i)].index)\r\n",
        "    \r\n",
        "\r\n",
        "    df = new_df.drop(df[df['author_name']=='root'].index)\r\n",
        "  #  df['author_name'] = df['author_name'].str.strip()\r\n",
        "    df['author_name'] = df['author_name'].str.strip()\r\n",
        "    return df\r\n",
        "  new_df = clean_auth_names()\r\n",
        "\r\n",
        "\r\n",
        "  def cleanhtml(raw_html):\r\n",
        "    if \"@\" not in raw_html:\r\n",
        "      cleanr = re.compile('<.*?>')\r\n",
        "      new_df.loc[new_df.email_id == raw_html,'email_id'] = re.sub(cleanr, '', raw_html)\r\n",
        "\r\n",
        "  def clean_emailids(new_df):\r\n",
        "    new_df['email_id'] = new_df['email_id'].str.lower()\r\n",
        "    new_df.drop(new_df[new_df['email_id'].str.contains(\"noreply\", na = False)].index, inplace = True)\r\n",
        "    #df = df.drop(df[df['email_id'].str.contains(\"\\*\\*\", na=False)].index)\r\n",
        "    \r\n",
        "    new_df['email_id'].apply(lambda x: cleanhtml(str(x)))\r\n",
        "    new_df['email_id'] = new_df['email_id'].str.split('@').str[0]\r\n",
        "    new_df['email_id'] = new_df['email_id'].str.replace(\"<\", \"\")\r\n",
        "\r\n",
        "    new_df.drop(new_df[new_df['email_id']==\"root\"].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id']==\"franta-git\"].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id']==\"count.apache.org\"].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id']==\"do-not-reply\"].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id']==\"github.coffee\"].index, inplace = True)\r\n",
        "  \r\n",
        "    new_df.drop(new_df[new_df['email_id']==\"dev-null\"].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id'].str.contains(\"-github\", na = False)].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id'].str.contains(\"\\+github\", na = False)].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id'].str.contains(\"\\+git\", na = False)].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id'].str.contains(\"-git\", na = False)].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id'].str.contains(\"github\", na = False)].index, inplace = True)\r\n",
        "    new_df.drop(new_df[new_df['email_id'].str.contains(\"git\", na = False)].index, inplace = True)\r\n",
        "\r\n",
        "    return new_df\r\n",
        "  new_df = clean_emailids(new_df)\r\n",
        "\r\n",
        "  com.author_name = com.author_name.str.lower()\r\n",
        "  new_df.author_name = new_df.author_name.str.lower()\r\n",
        "  new_df.author_name = new_df.author_name.astype('str')\r\n",
        "  new_df.email_id = new_df.email_id.astype('str')\r\n",
        "  #comma separated useless entries\r\n",
        "  new_df = new_df[~new_df.author_name.apply(lambda x: len(x.split(\",\")) > 2)]\r\n",
        "\r\n",
        "  #removing author names with two entries because they don't exist in the exhaustive list of committers\r\n",
        "  new_df = new_df[~new_df.author_name.apply(lambda x: \"@\" in x and len(x.split(\",\")) >= 2)]\r\n",
        "\r\n",
        "  #handling names and email_ids in brackets\r\n",
        "  def info_from_brac(x):\r\n",
        "    ind = re.search(r'\\(.*\\)', str(x)).span()\r\n",
        "    a = x[ind[0] + 1: ind[1]-1]\r\n",
        "    b = x[:ind[0]]\r\n",
        "    if \"@\" in a:\r\n",
        "      s = a.split(\"@\")\r\n",
        "      if \"\" not in s and len(s) > 1 and new_df.loc[new_df.author_name == x, \"email_id\"].isna().any():\r\n",
        "        id = s[0]\r\n",
        "        new_df.loc[new_df.author_name == x, \"email_id\"] = \" \".join(id.split())\r\n",
        "      new_df.loc[new_df.author_name == x, \"author_name\"] = \" \".join(b.split())\r\n",
        "    elif \"@\" in b:\r\n",
        "      s = b.split(\"@\")\r\n",
        "      if \"\" not in s and len(s) > 1 and new_df.loc[new_df.author_name == x, \"email_id\"].isna().any():\r\n",
        "        id = s[0]\r\n",
        "        new_df.loc[new_df.author_name == x, \"email_id\"] = \" \".join(id.split())\r\n",
        "      new_df.loc[new_df.author_name == x, \"author_name\"] = \" \".join(a.split())\r\n",
        "\r\n",
        "  new_df[(new_df.author_name.str.contains(\"@\"))&(new_df.author_name.str.contains(\"\\(\"))].author_name.apply(lambda x: info_from_brac(x));\r\n",
        "\r\n",
        "  #removing unwanted patterns\r\n",
        "  new_df['author_name'] = new_df['author_name'].str.lower()\r\n",
        "  #replace_str = [\"&gt;\", \"&lt;\", \",\", \"email:\", \"\\):\", \" \\)\", \"=\", \"+\", \"#\", \"=\", \"\\[\", \"\\]\", \"?\", \"\\(\\)\\;\", \"\\);\", \";\"]\r\n",
        "  replace_str = [\"&gt;\", \"&lt;\", \",\", \"email:\", \"\\):\", \"/\", \"\\\\\", \"*\", \"$\", \"`\", \"\\'\", \"\\\"\", \"|\", \" \\)\", \"=\", \"+\", \"#\", \"=\", \"\\[\", \"\\]\", \"?\", \"\\(\\)\\;\", \"\\);\", \";\"]\r\n",
        "  for i in replace_str:\r\n",
        "    new_df['author_name'] = new_df['author_name'].str.replace(i,\"\")\r\n",
        "    com['author_name'] = com['author_name'].str.replace(i,\"\")\r\n",
        "\r\n",
        "  new_df['author_name'] = new_df['author_name'].str.replace(\"  \",\" \")\r\n",
        "  bot_str = ['\\[bot\\]', 'buildbot', 'nicerobot', 'github bot', '-bot', 'github actions bot', 'mergebot', 'renovate bot', 'automated github actions', 'auth of last commit', '4 immediate children', 'utf-8', 'entry get author', 'gg@localhost']\r\n",
        "  for i in bot_str:\r\n",
        "    new_df = new_df.drop(new_df[new_df['author_name'].str.contains(i)].index)\r\n",
        "  new_df = new_df.drop(new_df[new_df['author_name']=='root'].index)\r\n",
        "\r\n",
        "  new_df['author_name'] = new_df['author_name'].apply(lambda x: \" \".join(x.split()))\r\n",
        "\r\n",
        "\r\n",
        "  #moving user_ids from author_name to email_id\r\n",
        "  def replace_id_in_author(x):\r\n",
        "    for i in new_df.loc[new_df.author_name == x].index:\r\n",
        "      if new_df.loc[new_df.index == i, \"email_id\"].isna().any(): \r\n",
        "        new_df.loc[new_df.index == i, \"email_id\"] = x\r\n",
        "        new_df.loc[new_df.index == i, \"author_name\"] = com[com.user_ids == x].author_name.values[0].lower()\r\n",
        "\r\n",
        "  new_df[new_df.author_name.isin(com.user_ids.values)].author_name.apply(lambda x: replace_id_in_author(x))\r\n",
        "\r\n",
        "  #same as above but for non-NaNs in email_id\r\n",
        "  new_rows = []\r\n",
        "  def get_dict_for_rows(x):\r\n",
        "    for i in new_df.loc[new_df.author_name == x].index:\r\n",
        "      dit = new_df[new_df.index == i].to_dict(orient = 'records')[0]\r\n",
        "      dit[\"email_id\"] = x\r\n",
        "      dit[\"author_name\"] = com[com.user_ids == x].author_name.values[0]\r\n",
        "      new_df.loc[new_df.index == i, \"author_name\"] = com[com.user_ids == x].author_name.values[0].lower()\r\n",
        "      new_rows.append(dit)\r\n",
        "\r\n",
        "  new_df[new_df.author_name.isin(com.user_ids.values)].author_name.apply(lambda x: get_dict_for_rows(x));\r\n",
        "  new_df = pd.concat([new_df, pd.DataFrame(new_rows)])\r\n",
        "\r\n",
        "  #handling entries with \"@\" in author_name\r\n",
        "  rem = [\"@gregfranko\", \"@pah\", \"jason moon - @jsonmoon\", \"cloudbees dev@cloud\", \"smashew @ 2013-08-26\", \r\n",
        "        \"rich @ radics\", \"tim urberg - tim_urberg@yahoo.com\", \"_ liuyu66@\", \"trevor a.k.a @rawkintrevo\", \"cedric.pemberton@gmail.colm\",\r\n",
        "        \"steve blackmon @steveblackmon\", \"nayananga@acerubuntu18.04\", \"idevai\", \"clebert suconic at redhat dot com\"]\r\n",
        "  new_df = new_df[~new_df.author_name.isin(rem)]\r\n",
        "\r\n",
        "  new_df.loc[new_df.author_name == \"jon haddad jon@jonhaddad.com\", \"email_id\"] = \"jon\"\r\n",
        "  new_df.loc[new_df.author_name == \"jon haddad jon@jonhaddad.com\", \"author_name\"] = \"jon haddad\"\r\n",
        "  new_df.loc[new_df.author_name == \"andrzej bialecki ab@getopt.org\", \"email_id\"] = \"ab\"\r\n",
        "  new_df.loc[new_df.author_name == \"andrzej bialecki ab@getopt.org\", \"author_name\"] = \"andrzej bialecki\"\r\n",
        "  new_df.loc[new_df.author_name == \"marc prud'hommeaux mprudhom@apache.org\", \"email_id\"] = \"mprudhom\"\r\n",
        "  new_df.loc[new_df.author_name == \"marc prud'hommeaux mprudhom@apache.org\", \"author_name\"] = \"marc prud'hommeaux\"\r\n",
        "  new_df.loc[new_df.author_name == \"julia wang jwang98052@yahoo.com\", \"email_id\"] = \"jwang98052\"\r\n",
        "  new_df.loc[new_df.author_name == \"julia wang jwang98052@yahoo.com\", \"author_name\"] = \"julia wang\"\r\n",
        "  new_df.loc[new_df.author_name == \"markus weimer weimer@apache.org\", \"email_id\"] = \"weimer\"\r\n",
        "  new_df.loc[new_df.author_name == \"markus weimer weimer@apache.org\", \"author_name\"] = \"markus weimer\"\r\n",
        "  new_df.loc[new_df.author_name == \"henri yandell bayard@generationjava.com\", \"email_id\"] = \"bayard\"\r\n",
        "  new_df.loc[new_df.author_name == \"henri yandell bayard@generationjava.com\", \"author_name\"] = \"henri yandell\"\r\n",
        "\r\n",
        "  if pr == \"cassandra\":\r\n",
        "    more_rows = [{\"proj_name\" : \"cassandra\", \"date_time\" : \"2020-04-01 15:16:00\",\"author_name\" : \"jon haddad\", \"email_id\" : \"rustyrazorblade\"}]\r\n",
        "    new_df = pd.concat([new_df, pd.DataFrame(more_rows)])\r\n",
        "  if pr == \"reef\":\r\n",
        "    more_rows = [{\"proj_name\" : \"reef\", \"date_time\" : \"2015-07-15 16:59:00\",\"author_name\" : \"julia wang\", \"email_id\" : \"juliaw\"}]\r\n",
        "    new_df = pd.concat([new_df, pd.DataFrame(more_rows)])\r\n",
        "\r\n",
        "  def add_id_to_email(x):\r\n",
        "    sp_temp = x\r\n",
        "    if len(x.split(maxsplit = 1)) > 1:\r\n",
        "      sp_temp = x.split()[1]\r\n",
        "      sp_temp = \" \".join(sp_temp.split())\r\n",
        "    sp = x.split(\"@\")[0]\r\n",
        "    sp = \" \".join(sp.split())\r\n",
        "    for i in new_df.loc[new_df.author_name == x].index:\r\n",
        "      if new_df.loc[new_df.index == i, \"email_id\"].isna().any():\r\n",
        "        new_df.loc[new_df.index == i, \"email_id\"] = sp\r\n",
        "        if sp in com.user_ids.values:\r\n",
        "          new_df.loc[new_df.index == i, \"author_name\"] = com.loc[com.user_ids == sp, \"author_name\"].values[0].lower()\r\n",
        "\r\n",
        "  new_df[new_df.author_name.str.contains(\"@\")].author_name.apply(lambda x: add_id_to_email(x));\r\n",
        "\r\n",
        "  new_rows_2 = []\r\n",
        "  def get_dict_for_rows_2(x):\r\n",
        "    sp_temp = x\r\n",
        "    if len(x.split(maxsplit = 1)) > 1:\r\n",
        "      sp_temp = x.split()[1]\r\n",
        "      sp_temp = \" \".join(sp_temp.split())\r\n",
        "    sp = x.split(\"@\")[0]\r\n",
        "    sp = \" \".join(sp.split())\r\n",
        "    for i in new_df.loc[new_df.author_name == x].index:\r\n",
        "      a = new_df.loc[new_df.index == i, \"email_id\"].values[0].split(\"@\")[0]\r\n",
        "      a = \" \".join(a.split())\r\n",
        "      if a == sp:\r\n",
        "        if sp in com.user_ids.values:\r\n",
        "          new_df.loc[new_df.index == i, \"author_name\"] = com.loc[com.user_ids == sp, \"author_name\"].values[0].lower()\r\n",
        "        else:\r\n",
        "          new_df.loc[new_df.index == i, \"author_name\"] = sp\r\n",
        "      else:\r\n",
        "        dit = new_df[new_df.index == i].to_dict(orient = 'records')[0]\r\n",
        "        \r\n",
        "        dit[\"email_id\"] = sp\r\n",
        "        if sp in com.user_ids.values:\r\n",
        "          dit[\"author_name\"] = com[com.user_ids == sp].author_name.values[0]\r\n",
        "          new_df.loc[new_df.index == i, \"author_name\"] = com[com.user_ids == sp].author_name.values[0].lower()\r\n",
        "        elif a in com.user_ids.values:\r\n",
        "          dit[\"author_name\"] = com[com.user_ids == a].author_name.values[0]\r\n",
        "          new_df.loc[new_df.index == i, \"author_name\"] = com[com.user_ids == a].author_name.values[0].lower()\r\n",
        "        else:\r\n",
        "          dit[\"author_name\"] = sp\r\n",
        "          new_df.loc[new_df.index == i, \"author_name\"] = a\r\n",
        "        new_rows_2.append(dit)\r\n",
        "\r\n",
        "  new_df[new_df.author_name.str.contains(\"@\")].author_name.apply(lambda x: get_dict_for_rows_2(x));\r\n",
        "  new_df = pd.concat([new_df, pd.DataFrame(new_rows_2)])\r\n",
        "\r\n",
        "  new_df.loc[new_df.author_name == \"thierry kormann\", \"email_id\"] = \"tkormann\"\r\n",
        "  new_df.loc[new_df.author_name == \"anirban roy\", \"email_id\"] = \"anirbanroy\"\r\n",
        "\r\n",
        "  new_df.reset_index(inplace = True)\r\n",
        "\r\n",
        "  #filling NAs in email id using the json file data if the author name is present in the json data file\r\n",
        "  def fill_na_email(x):\r\n",
        "    for i in new_df.loc[new_df.author_name == x].index:\r\n",
        "      if new_df.loc[new_df.index == i, \"email_id\"].isna().any() and x in com.author_name.values:\r\n",
        "        new_df.loc[new_df.index == i, \"email_id\"] = com[com.author_name == x].user_ids.values[0].lower()\r\n",
        "\r\n",
        "  new_df[new_df.email_id.isna()].author_name.apply(lambda x: fill_na_email(x))\r\n",
        "\r\n",
        "  new_df.loc[new_df.email_id.apply(lambda x: len(x) == 1), \"email_id\"] = new_df.loc[new_df.email_id.apply(lambda x: len(x) == 1), \"author_name\"].apply(lambda x : com[com.author_name == x].user_ids.values[0].lower() if x in com.author_name.values else np.nan)\r\n",
        "  \r\n",
        "  new_df.loc[new_df.email_id == \"me\", \"email_id\"] = new_df.loc[new_df.email_id == \"me\", \"author_name\"].apply(lambda x : com[com.author_name == x].user_ids.values[0].lower() if x in com.author_name.values else np.nan)\r\n",
        "\r\n",
        "  new_df = new_df[new_df.email_id != \"dev\"]\r\n",
        "  new_df = new_df[~new_df.author_name.str.isnumeric()]\r\n",
        "  new_df = new_df[new_df.author_name != \"\"]\r\n",
        "  new_df = new_df[new_df.author_name != \"nan\"]\r\n",
        "\r\n",
        "  replace_str = [\"&gt;\", \"&lt;\", \",\", \"email:\", \"\\):\", \"/\", \"\\\\\", \"*\", \"$\", \"`\", \"\\'\", \"\\\"\", \"|\", \" \\)\", \"=\", \"+\", \"#\", \"=\", \"\\[\", \"\\]\", \"?\", \"\\(\\)\\;\", \"\\);\", \";\", \">\", \"<\"]\r\n",
        "  for i in replace_str:\r\n",
        "    new_df['author_name'] = new_df['author_name'].str.replace(i,\"\")\r\n",
        "    #new_df['email_id'] = new_df['email_id'].str.replace(i,\"\")\r\n",
        "\r\n",
        "  new_df = new_df[new_df.author_name != \"\"]\r\n",
        "  new_df = new_df[new_df.email_id != \"\"]\r\n",
        "\r\n",
        "  proj_commit = pd.concat([proj_commit, new_df])\r\n",
        "\r\n",
        "proj_commit.author_name = proj_commit.author_name.str.replace(\"-\", \"\")\r\n",
        "proj_commit.to_csv(\"/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/final_df_curr_10.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVhKkWkANhdH"
      },
      "source": [
        "#more cleaning...\r\n",
        "#Merge preprocessed and from/sub df\r\n",
        "df_tot_commit = pd.read_csv('/content/drive/MyDrive/GG_Project_NLP/Data/commit_messages/final_df_curr_10.csv')\r\n",
        "df_from_sub = pd.read_csv('/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/commit_data_from_subject_10.csv')\r\n",
        "\r\n",
        "print(\"tot_commit_columns: \", df_tot_commit.columns)\r\n",
        "print(\"tot_commit_length: \", len(df_tot_commit))\r\n",
        "print(\"from_subject_columns: \", df_from_sub.columns)\r\n",
        "print(\"from_subject_length: \", len(df_from_sub))\r\n",
        "\r\n",
        "merged_df = pd.merge(df_tot_commit, df_from_sub,  how='left', on = ['proj_name', 'date_time'], validate='many_to_many')\r\n",
        "print(df_tot_commit.isna().sum().sort_values(ascending=False))\r\n",
        "\r\n",
        "#drop names with \"jira\" since they are not part of the committers\r\n",
        "merged_df.drop(merged_df[merged_df['from'].str.contains(\"(jira)\", na = False)].index, inplace = True)\r\n",
        "merged_df.drop(merged_df[merged_df['from'].str.contains(\"(JIRA)\", na = False)].index, inplace = True)\r\n",
        "merged_df.drop(merged_df[merged_df['from'].str.contains(\"(Jira)\", na = False)].index, inplace = True)\r\n",
        "merged_df.dropna(subset=['author_name','email_id'], how='all',inplace=True)\r\n",
        "\r\n",
        "#create dataframes with and without email NAs\r\n",
        "no_na_email = merged_df[~(merged_df['email_id'].isna())]\r\n",
        "na_email=merged_df[merged_df['email_id'].isna()]\r\n",
        "#na_email.to_csv('/content/drive/MyDrive/GG_Project_NLP/Data/commit_messages/NA_email_merged_updated_10.csv')\r\n",
        "\r\n",
        "#Manually filled the Nans and stored in the same csv file. Now merge with the df without nans in email\r\n",
        "merged_no_na_email = no_na_email.append(na_email, ignore_index=True)\r\n",
        "merged_no_na_email.drop_duplicates(subset=['proj_name','author_name', 'email_id', 'from'], inplace=True)\r\n",
        "merged_no_na_email.drop(columns=['Unnamed: 0_x','level_0', 'Unnamed: 0.1', 'Unnamed: 0_y', 'from', 'subject', 'commits_folder', 'Unnamed: 0'], inplace=True)\r\n",
        "\r\n",
        "\r\n",
        "merged_no_na_email.drop(index = [4106, 4405], inplace=True)\r\n",
        "#remove brackets and anything that's inside them\r\n",
        "merged_no_na_email['author_name'] = merged_no_na_email['author_name'].str.replace(r\"\\(.*\\)\",\"\")\r\n",
        "merged_no_na_email['author_name'] = merged_no_na_email['author_name'].str.replace(\"\\(\", \"\")\r\n",
        "merged_no_na_email[(merged_no_na_email['author_name'].str.contains(\"\\(\")) | (merged_no_na_email['author_name'].str.contains(\"\\)\"))]\r\n",
        "\r\n",
        "#removing entries with just numbers in the email id column\r\n",
        "merged_no_na_email = merged_no_na_email[~merged_no_na_email['email_id'].str.isnumeric()]\r\n",
        "#merged_no_na_email.to_csv('/content/drive/MyDrive/GG_Project_NLP/Data/commit_messages/final_cleaned_10.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBXYSN3hJTyw"
      },
      "source": [
        "#cleaning the hidden email ids in 'from' \r\n",
        "new_df_10 = pd.read_csv(\"/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/final_cleaned_10.csv\")\r\n",
        "from_df = new_df_10[['proj_name', 'author_name', 'email_id', 'from']]\r\n",
        "from_df.dropna(inplace = True)\r\n",
        "from_df = from_df[from_df['from'] != \"GitBox\"]\r\n",
        "#from_df['from'] = from_df['from'].apply(lambda x: x[:x.index(\".\")] if \".\" in x else x)\r\n",
        "from_df = from_df[from_df['from'] != \"\"]\r\n",
        "from_df = from_df[~from_df['from'].str.contains(\"Apache Jenkins\")]\r\n",
        "from_df = from_df[~from_df['from'].str.contains(\"github\")]\r\n",
        "from_df['from_ids'] = from_df['from'].apply(lambda x: x[:x.index(\".\")] if \".\" in x else x)\r\n",
        "from_df.to_csv(\"/content/gdrive/MyDrive/GG_Project_NLP/Data/commit_messages/final_from_df.csv\")\r\n",
        "from_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}